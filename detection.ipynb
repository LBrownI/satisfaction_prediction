{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrantes\n",
        "\n",
        "---\n",
        "* Karina Barrientos\n",
        "* kbarrientosb1@correo.uss.cl\n",
        "* 21.460.339-K\n",
        "---\n",
        "\n",
        "* Lucas Brown Ibieta\n",
        "* lbrowni@correo.uss.cl\n",
        "* 21.063.252-2\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVG9Gt70rJFX"
      },
      "source": [
        "# Solemne 3: Prediccion de satisfaccion de servicio en base a hábitos de compra\n",
        "\n",
        "Usted ha sido recientemente contratado como científico de datos en una tienda de venta de ropa online. Dado el gran volumen de ventas que tiene la tienda los asistentes de la empresa trabajan sin descanso ayudando a los clientes con el proceso de compra. Dado que recientemente se han empezado a registrar esperas muy largas para ser atendido por uno de los asistentes, a alguien en la junta directiva se le ocurrio que se podia ahorrar tiempo si los asistentes no realizaran una “breve” encuesta de satisfaccion a cada cliente. Esta encuensta se traduce internamente en un puntaje único, lo que ayudaria a predecirlo  a partir de datos de los clientes recogidos de manera automática, y si es cierto, a disminuir los tiempos de espera de los clientes por un asistente sin tener que contrar mas personas para ese cargo.\n",
        "\n",
        "El archivo dataset3.csv contiene un dataset con los resultados de información recogida de manera automática (17 variables) para 3900 clientes.\n",
        "\n",
        "*Con esta información, determine si es posible predecir de manera robusta un predictor de puntaje de satissfacionen a partir de otra información que se recoge de manera automática para los clientes .*\n",
        "\n",
        "Deben asegurarse de que sus sistema generaliza  y que han usado el mejor algoritmo regrersor con los mejores parametros posibles para reolver esta tarea. Documenten el proceso y explique cada una de las decisiones que toma y que criterios las sustentan.\n",
        "\n",
        "# Tarea:\n",
        "Aprovechando la gran cantidad de datos existentes en el dataset, construya un sistema que a través de  algoritmos de regresión nos permita establecer la viabilidad de predecir el puntaje de satisfaccion a paritr de otra data de facil recoleccion.\n",
        "\n",
        "El procedimiento a seguir debe ser el siguiente:\n",
        "\n",
        "1. Utilicen al menos 3 algoritmos de los explicados en la unidad 3 con distintos parametros y los 17 descriptores del dataset. Asegurense de las capacidades de generalización de cada algoritmo/set de parametros y comparen el desempeño de todos ellos.\n",
        "\n",
        "2. Usen al menos un metodo para seleccionar los mejores 10 descriptores y compare el desempeño con las versiones de los mismos algoritmos del punto anteriors. Expliquen la diferencia en desempeños\n",
        "\n",
        "3. Estudien ahora el efecto de normalizar los datos. ¿Los parametros optimos y el desempeño son distintos?, expliquen las diferencias observadas\n",
        "       \n",
        "Se entrega el jupyter notebook. Use celdas con texto para justificar y explicar cada paso. Asegurense de que la primera celda contiene el Nombre completo, email y rut de los miembros del equipo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFGfOFVuE17n"
      },
      "source": [
        "![alt text](Untitled.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Importación de Librerías y Simulación de Datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# 1. SIMULACIÓN DE DATOS (dataset3.csv)\n",
        "# Nota: En un escenario real, usaríamos pd.read_csv('dataset3.csv')\n",
        "print(\"Generando datos simulados para imitar 'dataset3.csv'...\")\n",
        "print(\"  - 3900 Clientes\")\n",
        "print(\"  - 17 Variables descriptores\")\n",
        "print(\"  - 1 Variable objetivo (Puntaje de Satisfacción)\")\n",
        "\n",
        "X, y = make_regression(n_samples=3900, n_features=17, n_informative=10, \n",
        "                       noise=20, random_state=42)\n",
        "\n",
        "# Convertir a DataFrame para mejor manejo y visualización\n",
        "feature_names = [f'Var_{i+1}' for i in range(17)]\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['Satisfaccion_Score'] = y\n",
        "\n",
        "print(\"Primeras filas del dataset generado:\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "En este primer paso, importamos las herramientas necesarias (sklearn, pandas) y generamos un dataset sintético que imita las características del dataset3.csv lo cual fué mencionado en el problema (3900 filas, 17 variables). Esto nos permite establecer la base de datos sobre la que se trabaja durante el proyecto. Usamos make_regression para crear una relación matemática subyacente con algo de ruido, simulando la variabilidad real de los datos de clientes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. Preparación de Datos (Train/Test Split)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[feature_names], \n",
        "    df['Satisfaccion_Score'], \n",
        "    test_size=0.2,  # 20% para test\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Datos de Entrenamiento: {X_train.shape[0]} muestras\")\n",
        "print(f\"Datos de Prueba: {X_test.shape[0]} muestras\")\n",
        "\n",
        "# Inicializamos una lista para guardar los resultados de cada experimento\n",
        "resultados = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aquí dividimos los datos en dos conjuntos: Entrenamiento (80%) y Prueba (20%). Esta separación es muy importante para asegurarse de que el sistema generalize bien. Si evaluáramos el modelo con los mismos datos que usamos para entrenarlo, obtendríamos resultados engañosos ya que solo mira los datos que ya conoce (overfitting). Los datos de prueba actúan como clientes \"nuevos\" que el sistema nunca ha visto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
